{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import torchinfo\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "from pytz import timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "RANDOM_SEED = 4242\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "IMG_SIZE = 32\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# 하이퍼파리미터-학습률 스케줄링 설정\n",
    "def lr_schedule(epoch):\n",
    "    if epoch <= 2:\n",
    "        lr = 5e-4\n",
    "    elif epoch <= 5:\n",
    "        lr = 2e-4\n",
    "    elif epoch <= 9:\n",
    "        lr = 5e-5\n",
    "    else:\n",
    "        lr = 1e-5\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 정확도를 계산하는 함수\n",
    "def get_accuracy(model, data_loader, device):\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            probabilities = F.softmax(model(images), dim=-1)\n",
    "            _, predicted_labels = torch.max(probabilities, 1)\n",
    "\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted_labels == labels).sum()\n",
    "    return correct_predictions.float() / total_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 손실과 검증 손실을 시각화\n",
    "def plot_loss(train_loss, val_loss):\n",
    "    plt.style.use(\"grayscale\")\n",
    "    train_loss = np.array(train_loss)\n",
    "    val_loss = np.array(val_loss)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 4.5))\n",
    "    ax.plot(train_loss, color=\"green\", label=\"Training Loss\")\n",
    "    ax.plot(val_loss, color=\"red\", label=\"Validation Loss\")\n",
    "    ax.set(title=\"Loss Over Epochs\", xlabel=\"EPOCH\", ylabel=\"LOSS\")\n",
    "    ax.legend()\n",
    "    fig.show()\n",
    "    plt.style.use(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 함수\n",
    "def train(train_loader, model, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    epoch_loss = total_loss / len(train_loader.dataset)\n",
    "    return model, optimizer, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 데이터셋을 사용하여 모델의 성능을 평가\n",
    "def validate(valid_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, labels in valid_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 순전파와 손실 기록하기\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "\n",
    "    epoch_loss = total_loss / len(valid_loader.dataset)\n",
    "    return model, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 학습 루프\n",
    "def training_loop(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    epochs,\n",
    "    device,\n",
    "    print_every=1,\n",
    "):\n",
    "\n",
    "    best_loss = 1e10\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        new_lr = lr_schedule(epoch)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = new_lr\n",
    "\n",
    "        # training\n",
    "        model, optimizer, train_loss = train(\n",
    "            train_loader, model, criterion, optimizer, device\n",
    "        )\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # validation\n",
    "        with torch.no_grad():\n",
    "            model, valid_loss = validate(valid_loader, model, criterion, device)\n",
    "            valid_losses.append(valid_loss)\n",
    "\n",
    "        if epoch % print_every == (print_every - 1):\n",
    "\n",
    "            train_acc = get_accuracy(model, train_loader, device=device)\n",
    "            valid_acc = get_accuracy(model, valid_loader, device=device)\n",
    "\n",
    "            print(\n",
    "                datetime.now(timezone(\"Asia/Seoul\")).time().replace(microsecond=0),\n",
    "                \"--- \",\n",
    "                f\"Epoch: {epoch}\\t\"\n",
    "                f\"Train loss: {train_loss:.4f}\\t\"\n",
    "                f\"Valid loss: {valid_loss:.4f}\\t\"\n",
    "                f\"Train accuracy: {100 * train_acc:.2f}\\t\"\n",
    "                f\"Valid accuracy: {100 * valid_acc:.2f}\",\n",
    "            )\n",
    "\n",
    "    plot_loss(train_losses, valid_losses)\n",
    "\n",
    "    return model, optimizer, (train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet5 모델 정의\n",
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.pool4 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv5 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1)\n",
    "        self.fc6 = nn.Linear(120, 84)\n",
    "        self.fc7 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.tanh(x)\n",
    "\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.tanh(x)\n",
    "\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = F.tanh(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc6(x)\n",
    "        x = F.tanh(x)\n",
    "\n",
    "        logits = self.fc7(x)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)>\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error downloading train-images-idx3-ubyte.gz",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m)), transforms\u001b[38;5;241m.\u001b[39mToTensor()])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 데이터셋 다운로드 및 생성\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMNIST\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmnist_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m valid_dataset \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mMNIST(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmnist_data\u001b[39m\u001b[38;5;124m\"\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 데이터 로더 정의\u001b[39;00m\n",
      "File \u001b[0;32m/goinfre/michang/CV_Sys_DL/myenv/lib/python3.10/site-packages/torchvision/datasets/mnist.py:99\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_exists():\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/goinfre/michang/CV_Sys_DL/myenv/lib/python3.10/site-packages/torchvision/datasets/mnist.py:195\u001b[0m, in \u001b[0;36mMNIST.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 195\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError downloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error downloading train-images-idx3-ubyte.gz"
     ]
    }
   ],
   "source": [
    "# transforms 정의하기\n",
    "transform = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
    "\n",
    "# 데이터셋 다운로드 및 생성\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"mnist_data\", train=True, transform=transform, download=True\n",
    ")\n",
    "\n",
    "valid_dataset = datasets.MNIST(root=\"mnist_data\", train=False, transform=transform)\n",
    "\n",
    "# 데이터 로더 정의\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# 불러온 MNIST 데이터 확인\n",
    "ROW_IMG = 10\n",
    "N_ROWS = 5\n",
    "\n",
    "fig = plt.figure()\n",
    "for index in range(1, ROW_IMG * N_ROWS + 1):\n",
    "    plt.subplot(N_ROWS, ROW_IMG, index)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(train_dataset.data[index], cmap=\"gray_r\")\n",
    "\n",
    "fig.suptitle(\"MNIST Dataset - preview\")\n",
    "\n",
    "# 데이터셋 크기 출력\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")  # Train dataset size: 60000\n",
    "print(\n",
    "    f\"Validation dataset size: {len(valid_dataset)}\"\n",
    ")  # Validation dataset size: 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = LeNet5(NUM_CLASSES).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_schedule(0))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "torchinfo.summary(model, input_size=(1, 1, 32, 32))\n",
    "\n",
    "model, optimizer, _ = training_loop(\n",
    "    model, criterion, optimizer, train_loader, valid_loader, EPOCHS, DEVICE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
